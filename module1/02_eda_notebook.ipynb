{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1 - Step 2: Exploratory Data Analysis & Feature Engineering\n",
    "\n",
    "#### Bank Marketing Dataset\n",
    "\n",
    "**Goal:** Predict if client subscribes to term deposit (yes/no)\n",
    "\n",
    "**Size:** 41,188 records, 20 features | **Balance:** 11% yes, 89% no\n",
    "\n",
    "*Source: Portuguese bank direct marketing campaigns (phone calls), May 2008 - Nov 2010*\n",
    "\n",
    "---\n",
    "\n",
    "## Workshop Learning Objectives\n",
    "\n",
    "In this notebook, you will:\n",
    "1. Perform comprehensive exploratory data analysis (EDA)\n",
    "2. Understand the relationship between features and target variable\n",
    "3. Quickly explore 2-3 baseline models\n",
    "4. Extract and analyze feature importance\n",
    "5. Engineer new features based on insights\n",
    "6. Validate that new features improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Start timer\n",
    "notebook_start_time = time.time()\n",
    "start_timestamp = datetime.now()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NOTEBOOK EXECUTION STARTED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Start Time: {start_timestamp.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical tests\n",
    "from scipy import stats\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    f1_score, roc_auc_score, classification_report\n",
    ")\n",
    "\n",
    "# CML specific\n",
    "import cml.data_v1 as cmldata\n",
    "\n",
    "# Custom utilities\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from shared_utils import (\n",
    "    DATALAKE_CONFIG,\n",
    "    get_spark_session\n",
    ")\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úì All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data from Data Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure connection to data lake\n",
    "database_name = DATALAKE_CONFIG[\"database_name\"] \n",
    "table_name = DATALAKE_CONFIG[\"table_name\"]\n",
    "username = os.environ.get('HADOOP_USER_NAME') # use HADOOP_USER_NAME env to grab executing user if available\n",
    "if not username:\n",
    "    username = os.environ[\"PROJECT_OWNER\"] # fallback to project owner\n",
    "\n",
    "CONNECTION_NAME = os.environ.get(\"CONNECTION_NAME\", \"se-aws-edl\")\n",
    "\n",
    "# Connect to Iceberg table\n",
    "conn = cmldata.get_connection(CONNECTION_NAME)\n",
    "spark = conn.get_spark_session()\n",
    "\n",
    "# Build full table path\n",
    "full_db = f\"{database_name}_{username}\".upper()\n",
    "full_table = f\"{table_name}_{username}\".upper()\n",
    "full_path = f\"{full_db}.{full_table}\"\n",
    "\n",
    "print(f\"Loading data from: {full_path}\")\n",
    "spark_df = spark.table(full_path)\n",
    "df = spark_df.toPandas()\n",
    "\n",
    "print(f\"‚úì Dataset loaded successfully!\")\n",
    "print(f\"  Shape: {df.shape}\")\n",
    "print(f\"  Rows: {df.shape[0]:,} | Columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Data Understanding\n",
    "\n",
    "Let's get a quick overview of our dataset structure and quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df)\n",
    "else:\n",
    "    print(\"‚úì No missing values detected!\\n Typically we'll have missing values and have to address them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TARGET VARIABLE DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "target_counts = df['y'].value_counts()\n",
    "target_pct = df['y'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(f\"\\nSubscribed (yes): {target_counts['yes']:,} ({target_pct['yes']:.2f}%)\")\n",
    "print(f\"Not Subscribed (no): {target_counts['no']:,} ({target_pct['no']:.2f}%)\")\n",
    "print(f\"\\nClass Imbalance Ratio: {target_counts['no'] / target_counts['yes']:.2f}:1\")\n",
    "print(\"\\n‚ö†Ô∏è  Note: This is an imbalanced dataset. We'll need to consider this in modeling.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Univariate Analysis - Numerical Features\n",
    "\n",
    "Let's examine the distribution of numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols.remove(\"duration\") # duration is NOT a feature - only known at the time of sale/non sale\n",
    "print(f\"Numerical Features ({len(numeric_cols)}): {numeric_cols}\")\n",
    "\n",
    "# Descriptive statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DESCRIPTIVE STATISTICS FOR NUMERICAL FEATURES\")\n",
    "print(\"=\"*60)\n",
    "display(df[numeric_cols].describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots for key numerical features\n",
    "key_numeric = ['age', 'campaign', 'pdays', 'previous', \n",
    "               'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "\n",
    "# Filter to existing columns\n",
    "key_numeric = [col for col in key_numeric if col in df.columns]\n",
    "\n",
    "fig, axes = plt.subplots(5, 2, figsize=(15, 20))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(key_numeric):\n",
    "    if idx < len(axes):\n",
    "        # Histogram with KDE\n",
    "        axes[idx].hist(df[col].dropna(), bins=50, edgecolor='black', \n",
    "                      alpha=0.7, color='steelblue', density=True)\n",
    "        \n",
    "        # Add KDE line\n",
    "        df[col].dropna().plot(kind='kde', ax=axes[idx], color='red', linewidth=2, secondary_y=True)\n",
    "        \n",
    "        axes[idx].set_title(f'{col.upper()} Distribution', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel(col, fontsize=10)\n",
    "        axes[idx].set_ylabel('Frequency', fontsize=10)\n",
    "        axes[idx].grid(alpha=0.3)\n",
    "        \n",
    "        # Add statistics text\n",
    "        mean_val = df[col].mean()\n",
    "        median_val = df[col].median()\n",
    "        axes[idx].axvline(mean_val, color='green', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.2f}')\n",
    "        axes[idx].axvline(median_val, color='orange', linestyle='--', linewidth=2, label=f'Median: {median_val:.2f}')\n",
    "        axes[idx].legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä KEY OBSERVATIONS:\")\n",
    "print(\"  ‚Ä¢ 'pdays' has many 999 values (customer not previously contacted)\")\n",
    "print(\"  ‚Ä¢ 'campaign' shows most customers contacted 1-3 times\")\n",
    "print(\"  ‚Ä¢ Economic indicators show clustering around specific values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Univariate Analysis - Categorical Features\n",
    "\n",
    "Let's examine the distribution of categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of categorical features\n",
    "cat_to_plot = ['job', 'marital', 'education', 'default', 'housing', 'loan', \n",
    "               'contact', 'month', 'day_of_week', 'poutcome']\n",
    "cat_to_plot = [col for col in cat_to_plot if col in df.columns]\n",
    "\n",
    "fig, axes = plt.subplots(5, 2, figsize=(16, 20))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(cat_to_plot):\n",
    "    if idx < len(axes):\n",
    "        value_counts = df[col].value_counts()\n",
    "        \n",
    "        # Bar plot\n",
    "        value_counts.plot(kind='barh', ax=axes[idx], color='teal', alpha=0.7)\n",
    "        axes[idx].set_title(f'{col.upper()} Distribution', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel('Count', fontsize=10)\n",
    "        axes[idx].set_ylabel(col, fontsize=10)\n",
    "        axes[idx].grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, v in enumerate(value_counts):\n",
    "            axes[idx].text(v + 100, i, f'{v:,}', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bivariate Analysis - Target vs Numerical Features\n",
    "\n",
    "How do numerical features relate to subscription outcomes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (16, 12)\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 14))\n",
    "fig.suptitle('Key Predictors of Term Deposit Subscription (Excluding Duration)', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "# ============================================\n",
    "# 1. CAMPAIGN FATIGUE\n",
    "# ============================================\n",
    "ax1 = axes[0, 0]\n",
    "\n",
    "# Group campaigns for cleaner visualization\n",
    "df['campaign_group'] = pd.cut(df['campaign'], \n",
    "                              bins=[0, 2, 5, 10, 100], \n",
    "                              labels=['1-2 contacts', '3-5 contacts', '6-10 contacts', '10+ contacts'])\n",
    "\n",
    "campaign_data = df.groupby('campaign_group', observed=True).agg({\n",
    "    'y': [lambda x: (x == 'yes').mean() * 100, 'count']\n",
    "}).reset_index()\n",
    "campaign_data.columns = ['campaign_group', 'conversion_rate', 'count']\n",
    "\n",
    "bars = ax1.bar(campaign_data['campaign_group'], campaign_data['conversion_rate'], \n",
    "               color=['#2ecc71', '#f39c12', '#e74c3c', '#8b0000'], edgecolor='black', linewidth=1.5)\n",
    "ax1.axhline(y=11.3, color='blue', linestyle='--', linewidth=2, label='Overall Rate (11.3%)')\n",
    "ax1.set_ylabel('Conversion Rate (%)', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Number of Contacts in Campaign', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Campaign Fatigue: More Contacts = Lower Success', fontsize=13, fontweight='bold')\n",
    "ax1.legend()\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, (bar, count) in enumerate(zip(bars, campaign_data['count'])):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "            f'n={int(count)}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# ============================================\n",
    "# 2. PREVIOUS CAMPAIGN OUTCOME\n",
    "# ============================================\n",
    "ax2 = axes[0, 1]\n",
    "\n",
    "poutcome_data = df.groupby('poutcome').agg({\n",
    "    'y': [lambda x: (x == 'yes').mean() * 100, 'count']\n",
    "}).reset_index()\n",
    "poutcome_data.columns = ['poutcome', 'conversion_rate', 'count']\n",
    "\n",
    "colors = {'success': '#2ecc71', 'failure': '#e74c3c', 'nonexistent': '#95a5a6'}\n",
    "bar_colors = [colors.get(x, '#95a5a6') for x in poutcome_data['poutcome']]\n",
    "\n",
    "bars = ax2.bar(poutcome_data['poutcome'], poutcome_data['conversion_rate'], \n",
    "               color=bar_colors, edgecolor='black', linewidth=1.5)\n",
    "ax2.axhline(y=11.3, color='blue', linestyle='--', linewidth=2, label='Overall Rate')\n",
    "ax2.set_ylabel('Conversion Rate (%)', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Previous Campaign Outcome', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Previous Success = 65% Conversion!', fontsize=13, fontweight='bold')\n",
    "ax2.legend()\n",
    "\n",
    "for i, (bar, count) in enumerate(zip(bars, poutcome_data['count'])):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "            f'n={int(count)}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# ============================================\n",
    "# 3. CONTACT RECENCY (pdays < 999)\n",
    "# ============================================\n",
    "ax3 = axes[1, 0]\n",
    "\n",
    "df['contacted_before'] = df['pdays'] < 999\n",
    "recency_data = df.groupby('contacted_before').agg({\n",
    "    'y': [lambda x: (x == 'yes').mean() * 100, 'count']\n",
    "}).reset_index()\n",
    "recency_data.columns = ['contacted_before', 'conversion_rate', 'count']\n",
    "recency_data['label'] = recency_data['contacted_before'].map({False: 'Never Contacted', True: 'Contacted Before'})\n",
    "\n",
    "bars = ax3.bar(recency_data['label'], recency_data['conversion_rate'], \n",
    "               color=['#e74c3c', '#2ecc71'], edgecolor='black', linewidth=1.5)\n",
    "ax3.axhline(y=11.3, color='blue', linestyle='--', linewidth=2, label='Overall Rate')\n",
    "ax3.set_ylabel('Conversion Rate (%)', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Contact History', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Previously Contacted = 64% Conversion!', fontsize=13, fontweight='bold')\n",
    "ax3.legend()\n",
    "\n",
    "for i, (bar, count) in enumerate(zip(bars, recency_data['count'])):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "            f'n={int(count)}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# ============================================\n",
    "# 4. MONTH SEASONALITY\n",
    "# ============================================\n",
    "ax4 = axes[1, 1]\n",
    "\n",
    "month_order = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "month_data = df.groupby('month').agg({\n",
    "    'y': [lambda x: (x == 'yes').mean() * 100, 'count']\n",
    "}).reset_index()\n",
    "month_data.columns = ['month', 'conversion_rate', 'count']\n",
    "month_data['month'] = pd.Categorical(month_data['month'], categories=month_order, ordered=True)\n",
    "month_data = month_data.sort_values('month')\n",
    "\n",
    "# Color by performance\n",
    "colors_month = ['#2ecc71' if x > 30 else '#f39c12' if x > 15 else '#e74c3c' \n",
    "                for x in month_data['conversion_rate']]\n",
    "\n",
    "bars = ax4.bar(month_data['month'], month_data['conversion_rate'], \n",
    "               color=colors_month, edgecolor='black', linewidth=1.5)\n",
    "ax4.axhline(y=11.3, color='blue', linestyle='--', linewidth=2, label='Overall Rate')\n",
    "ax4.set_ylabel('Conversion Rate (%)', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('Month', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Seasonal Patterns: Mar, Sep, Oct, Dec Best', fontsize=13, fontweight='bold')\n",
    "ax4.legend()\n",
    "plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "# ============================================\n",
    "# 5. AGE GROUPS\n",
    "# ============================================\n",
    "ax5 = axes[2, 0]\n",
    "\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 30, 40, 50, 60, 100], \n",
    "                         labels=['<30', '30-40', '40-50', '50-60', '60+'])\n",
    "age_data = df.groupby('age_group', observed=True).agg({\n",
    "    'y': [lambda x: (x == 'yes').mean() * 100, 'count']\n",
    "}).reset_index()\n",
    "age_data.columns = ['age_group', 'conversion_rate', 'count']\n",
    "\n",
    "# Color by age\n",
    "colors_age = ['#3498db', '#95a5a6', '#95a5a6', '#95a5a6', '#2ecc71']\n",
    "\n",
    "bars = ax5.bar(age_data['age_group'], age_data['conversion_rate'], \n",
    "               color=colors_age, edgecolor='black', linewidth=1.5)\n",
    "ax5.axhline(y=11.3, color='blue', linestyle='--', linewidth=2, label='Overall Rate')\n",
    "ax5.set_ylabel('Conversion Rate (%)', fontsize=12, fontweight='bold')\n",
    "ax5.set_xlabel('Age Group', fontsize=12, fontweight='bold')\n",
    "ax5.set_title('Retirees (60+) Convert at 45%!', fontsize=13, fontweight='bold')\n",
    "ax5.legend()\n",
    "\n",
    "for i, (bar, count) in enumerate(zip(bars, age_data['count'])):\n",
    "    height = bar.get_height()\n",
    "    ax5.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "            f'n={int(count)}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# ============================================\n",
    "# 6. JOB TYPE (Top performing)\n",
    "# ============================================\n",
    "ax6 = axes[2, 1]\n",
    "\n",
    "job_data = df.groupby('job').agg({\n",
    "    'y': [lambda x: (x == 'yes').mean() * 100, 'count']\n",
    "}).reset_index()\n",
    "job_data.columns = ['job', 'conversion_rate', 'count']\n",
    "job_data = job_data.sort_values('conversion_rate', ascending=False).head(8)\n",
    "\n",
    "bars = ax6.barh(job_data['job'], job_data['conversion_rate'], \n",
    "                color='steelblue', edgecolor='black', linewidth=1.5)\n",
    "ax6.axvline(x=11.3, color='red', linestyle='--', linewidth=2, label='Overall Rate')\n",
    "ax6.set_xlabel('Conversion Rate (%)', fontsize=12, fontweight='bold')\n",
    "ax6.set_ylabel('Job Type', fontsize=12, fontweight='bold')\n",
    "ax6.set_title('Students & Retirees Lead', fontsize=13, fontweight='bold')\n",
    "ax6.legend()\n",
    "ax6.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY FINDINGS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Overall Conversion Rate: 11.3%\")\n",
    "print(f\"\\nTOP PREDICTORS:\")\n",
    "print(f\"1. Previous Success: 65% (5.8x baseline)\")\n",
    "print(f\"2. Contacted Before: 64% (5.7x baseline)\")\n",
    "print(f\"3. Campaign 1-2: 12% vs 6+: 2%\")\n",
    "print(f\"4. Age 60+: 45% (4.0x baseline)\")\n",
    "print(f\"5. March campaigns: 51% (4.5x baseline)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical comparison of means\n",
    "compare_cols = ['age','campaign', 'previous', 'pdays']\n",
    "compare_cols = [col for col in compare_cols if col in df.columns]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTICAL COMPARISON: SUBSCRIBED vs NOT SUBSCRIBED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for col in compare_cols:\n",
    "    yes_values = df[df['y'] == 'yes'][col].dropna()\n",
    "    no_values = df[df['y'] == 'no'][col].dropna()\n",
    "    \n",
    "    # T-test\n",
    "    t_stat, p_value = stats.ttest_ind(yes_values, no_values)\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'Feature': col,\n",
    "        'Mean (Yes)': yes_values.mean(),\n",
    "        'Mean (No)': no_values.mean(),\n",
    "        'Difference': yes_values.mean() - no_values.mean(),\n",
    "        'P-Value': p_value,\n",
    "        'Significant': '‚úì' if p_value < 0.001 else '‚úó'\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "display(comparison_df)\n",
    "\n",
    "print(\"\\nüìä KEY FINDINGS:\")\n",
    "print(\"  ‚Ä¢ 'duration' shows the strongest difference (subscribers have longer calls)\")\n",
    "print(\"  ‚Ä¢ 'pdays' differs significantly (previous contact matters)\")\n",
    "print(\"  ‚Ä¢ These features will likely be important for modeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bivariate Analysis - Target vs Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subscription rate by categorical features\n",
    "cat_features = ['job', 'marital', 'education', 'contact', 'month', 'poutcome']\n",
    "cat_features = [col for col in cat_features if col in df.columns]\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(cat_features):\n",
    "    if idx < len(axes):\n",
    "        # Calculate subscription rate per category\n",
    "        crosstab = pd.crosstab(df[col], df['y'], normalize='index') * 100\n",
    "        \n",
    "        # Sort by 'yes' rate\n",
    "        crosstab = crosstab.sort_values('yes', ascending=True)\n",
    "        \n",
    "        # Plot\n",
    "        crosstab['yes'].plot(kind='barh', ax=axes[idx], color='#2ecc71', alpha=0.8)\n",
    "        axes[idx].set_title(f'Subscription Rate by {col.upper()}', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel('Subscription Rate (%)', fontsize=10)\n",
    "        axes[idx].set_ylabel(col, fontsize=10)\n",
    "        axes[idx].grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for i, v in enumerate(crosstab['yes']):\n",
    "            axes[idx].text(v + 0.5, i, f'{v:.1f}%', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square test for categorical features\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHI-SQUARE TEST: CATEGORICAL FEATURES vs TARGET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "chi_square_results = []\n",
    "\n",
    "for col in cat_features:\n",
    "    contingency_table = pd.crosstab(df[col], df['y'])\n",
    "    chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "    \n",
    "    chi_square_results.append({\n",
    "        'Feature': col,\n",
    "        'Chi-Square': chi2,\n",
    "        'P-Value': p_value,\n",
    "        'Significant': '‚úì' if p_value < 0.001 else '‚úó'\n",
    "    })\n",
    "\n",
    "chi_df = pd.DataFrame(chi_square_results).sort_values('Chi-Square', ascending=False)\n",
    "display(chi_df)\n",
    "\n",
    "print(\"\\nüìä KEY FINDINGS:\")\n",
    "print(\"  ‚Ä¢ 'poutcome' (previous campaign outcome) is highly predictive\")\n",
    "print(\"  ‚Ä¢ 'contact' (communication type) shows strong association\")\n",
    "print(\"  ‚Ä¢ 'month' matters - certain months have better conversion rates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis\n",
    "\n",
    "Let's examine correlations between numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "corr_matrix = df[numeric_features].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix - Numerical Features', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify highly correlated features\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HIGHLY CORRELATED FEATURE PAIRS (|r| > 0.7)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "high_corr = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "            high_corr.append({\n",
    "                'Feature 1': corr_matrix.columns[i],\n",
    "                'Feature 2': corr_matrix.columns[j],\n",
    "                'Correlation': corr_matrix.iloc[i, j]\n",
    "            })\n",
    "\n",
    "if high_corr:\n",
    "    high_corr_df = pd.DataFrame(high_corr).sort_values('Correlation', ascending=False)\n",
    "    display(high_corr_df)\n",
    "    print(\"\\n‚ö†Ô∏è  These features are highly correlated and may cause multicollinearity.\")\n",
    "else:\n",
    "    print(\"No highly correlated feature pairs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Quick Model Exploration\n",
    "\n",
    "Let's train a few baseline models to understand which features are most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "print(\"Preparing data for modeling...\")\n",
    "\n",
    "# Create a copy\n",
    "df_model = df.copy()\n",
    "\n",
    "# Encode target\n",
    "df_model['y'] = (df_model['y'] == 'yes').astype(int)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = df_model.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df_model[col] = le.fit_transform(df_model[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# ‚ö†Ô∏è  CRITICAL: Exclude 'duration' from features\n",
    "# Duration is only known AFTER the call ends, so it cannot be used for prediction\n",
    "features_to_exclude = ['y', 'duration']\n",
    "feature_cols = [col for col in df_model.columns if col not in features_to_exclude]\n",
    "\n",
    "# Split features and target\n",
    "X = df_model[feature_cols]\n",
    "y = df_model['y']\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  IMPORTANT: 'duration' excluded from modeling\")\n",
    "print(\"   Reason: Only known after call ends - cannot use for real-time prediction\")\n",
    "\n",
    "X = df_model[feature_cols]\n",
    "y = df_model['y']\n",
    "\n",
    "# Convert category and bool columns to numeric\n",
    "X = X.copy()\n",
    "for col in X.select_dtypes(include=['category']).columns:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
    "for col in X.select_dtypes(include=['bool']).columns:\n",
    "    X[col] = X[col].astype(int)\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  IMPORTANT: 'duration' excluded from features...\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Data prepared!\")\n",
    "print(f\"  Training set: {X_train.shape[0]:,} samples\")\n",
    "print(f\"  Test set: {X_test.shape[0]:,} samples\")\n",
    "print(f\"  Features: {X_train.shape[1]}\")\n",
    "print(f\"\\nFeatures used: {list(X.columns[:5])}... ({len(X.columns)} total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING BASELINE MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc\n",
    "    })\n",
    "    \n",
    "    trained_models[name] = model\n",
    "    \n",
    "    print(f\"‚úì {name} trained!\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  F1-Score: {f1:.4f}\")\n",
    "    print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df.style.highlight_max(axis=0, subset=['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Bar chart of metrics\n",
    "results_df.set_index('Model')[['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']].plot(\n",
    "    kind='bar', ax=axes[0], alpha=0.8, rot=45\n",
    ")\n",
    "axes[0].set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Score', fontsize=12)\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# ROC-AUC comparison\n",
    "x_pos = np.arange(len(results_df))\n",
    "axes[1].bar(x_pos, results_df['ROC-AUC'], alpha=0.8, color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "axes[1].set_title('ROC-AUC Score Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('ROC-AUC Score', fontsize=12)\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(results_df['ROC-AUC']):\n",
    "    axes[1].text(i, v + 0.01, f'{v:.4f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä KEY OBSERVATIONS:\")\n",
    "print(\"  ‚Ä¢ All models perform reasonably well on this dataset\")\n",
    "print(\"  ‚Ä¢ XGBoost and Random Forest show strong performance\")\n",
    "print(\"  ‚Ä¢ Next: Let's examine feature importance to guide feature engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Analysis\n",
    "\n",
    "Now let's examine which ACTIONABLE features matter most (excluding duration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance from tree-based models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Random Forest importance\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': trained_models['Random Forest'].feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# XGBoost importance\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': trained_models['XGBoost'].feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Random Forest\n",
    "top_n = 15\n",
    "rf_importance.head(top_n).plot(x='Feature', y='Importance', kind='barh', \n",
    "                               ax=axes[0], color='steelblue', alpha=0.8, legend=False)\n",
    "axes[0].set_title('Top 15 Features - Random Forest', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Importance', fontsize=12)\n",
    "axes[0].set_ylabel('Feature', fontsize=12)\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# XGBoost\n",
    "xgb_importance.head(top_n).plot(x='Feature', y='Importance', kind='barh', \n",
    "                                ax=axes[1], color='darkorange', alpha=0.8, legend=False)\n",
    "axes[1].set_title('Top 15 Features - XGBoost', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Importance', fontsize=12)\n",
    "axes[1].set_ylabel('Feature', fontsize=12)\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features (Random Forest):\")\n",
    "display(rf_importance.head(10))\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features (XGBoost):\")\n",
    "display(xgb_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insights for feature engineering\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY INSIGHTS FOR FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìä Based on EDA and Feature Importance Analysis:\\n\")\n",
    "print(\"1. DURATION: Call duration is the #1 predictor\")\n",
    "print(\"   ‚Üí But it's only known AFTER the call ends (can't use for prediction)\")\n",
    "print(\"   ‚Üí We'll focus on other actionable features\\n\")\n",
    "\n",
    "print(\"2. ECONOMIC INDICATORS: Strong predictors (emp.var.rate, euribor3m, etc.)\")\n",
    "print(\"   ‚Üí Could create composite economic index\\n\")\n",
    "\n",
    "print(\"3. CONTACT HISTORY: pdays, previous, poutcome matter\")\n",
    "print(\"   ‚Üí Create engagement score combining these\\n\")\n",
    "\n",
    "print(\"4. AGE: Moderate importance\")\n",
    "print(\"   ‚Üí Create age groups for better interpretability\\n\")\n",
    "\n",
    "print(\"5. CAMPAIGN: Number of contacts matters\")\n",
    "print(\"   ‚Üí Create campaign efficiency metric\\n\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Feature Engineering\n",
    "\n",
    "Based on our analysis, let's create new features that could improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for feature engineering\n",
    "df_engineered = df.copy()\n",
    "\n",
    "print(\"Creating new features...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Feature 1: Customer Engagement Score\n",
    "print(\"\\n1. CUSTOMER ENGAGEMENT SCORE\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Combines:\")\n",
    "print(\"  ‚Ä¢ Previous contacts (previous)\")\n",
    "print(\"  ‚Ä¢ Days since last contact (pdays)\")\n",
    "print(\"  ‚Ä¢ Previous outcome (poutcome)\")\n",
    "print(\"\\nRationale: Customers with positive past interactions are more likely to convert\")\n",
    "\n",
    "def create_engagement_score(row):\n",
    "    \"\"\"\n",
    "    Create engagement score based on contact history.\n",
    "    Higher score = more engaged customer.\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    \n",
    "    # Previous contacts boost (capped at 5)\n",
    "    score += min(row['previous'], 5) * 2\n",
    "    \n",
    "    # Recent contact boost (pdays != 999 means previously contacted)\n",
    "    if row['pdays'] != 999:\n",
    "        # More recent = higher score (inverse relationship)\n",
    "        days_factor = 1 / (1 + row['pdays'] / 100)\n",
    "        score += days_factor * 5\n",
    "    \n",
    "    # Previous outcome boost\n",
    "    if row['poutcome'] == 'success':\n",
    "        score += 10\n",
    "    elif row['poutcome'] == 'failure':\n",
    "        score += 2  # At least they engaged\n",
    "    \n",
    "    return score\n",
    "\n",
    "df_engineered['engagement_score'] = df_engineered.apply(create_engagement_score, axis=1)\n",
    "print(f\"‚úì Created engagement_score\")\n",
    "print(f\"  Range: [{df_engineered['engagement_score'].min():.2f}, {df_engineered['engagement_score'].max():.2f}]\")\n",
    "print(f\"  Mean: {df_engineered['engagement_score'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 2: Economic Composite Index\n",
    "print(\"\\n2. ECONOMIC COMPOSITE INDEX\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Combines standardized economic indicators:\")\n",
    "print(\"  ‚Ä¢ Employment variation rate (emp.var.rate)\")\n",
    "print(\"  ‚Ä¢ Consumer price index (cons.price.idx)\")\n",
    "print(\"  ‚Ä¢ Consumer confidence index (cons.conf.idx)\")\n",
    "print(\"  ‚Ä¢ Euribor 3 month rate (euribor3m)\")\n",
    "print(\"  ‚Ä¢ Number employed (nr.employed)\")\n",
    "print(\"\\nRationale: Economic conditions affect subscription likelihood\")\n",
    "\n",
    "# Standardize economic indicators\n",
    "economic_features = ['emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "economic_features = [f for f in economic_features if f in df_engineered.columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_values = scaler.fit_transform(df_engineered[economic_features])\n",
    "\n",
    "# Create composite index (simple average of scaled values)\n",
    "df_engineered['economic_index'] = scaled_values.mean(axis=1)\n",
    "\n",
    "print(f\"‚úì Created economic_index\")\n",
    "print(f\"  Range: [{df_engineered['economic_index'].min():.2f}, {df_engineered['economic_index'].max():.2f}]\")\n",
    "print(f\"  Mean: {df_engineered['economic_index'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3: Age Group\n",
    "print(\"\\n3. AGE GROUP\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Categorical age groups for better interpretability:\")\n",
    "print(\"  ‚Ä¢ Young: 18-30\")\n",
    "print(\"  ‚Ä¢ Adult: 31-45\")\n",
    "print(\"  ‚Ä¢ Middle Age: 46-60\")\n",
    "print(\"  ‚Ä¢ Senior: 60+\")\n",
    "print(\"\\nRationale: Different age groups may have different subscription patterns\")\n",
    "\n",
    "def categorize_age(age):\n",
    "    if age <= 30:\n",
    "        return 'Young'\n",
    "    elif age <= 45:\n",
    "        return 'Adult'\n",
    "    elif age <= 60:\n",
    "        return 'Middle Age'\n",
    "    else:\n",
    "        return 'Senior'\n",
    "\n",
    "df_engineered['age_group'] = df_engineered['age'].apply(categorize_age)\n",
    "print(f\"‚úì Created age_group\")\n",
    "print(f\"\\nDistribution:\")\n",
    "print(df_engineered['age_group'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 4: Campaign Efficiency\n",
    "print(\"\\n4. CAMPAIGN EFFICIENCY RATIO\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Ratio of successful previous contacts to total campaign contacts\")\n",
    "print(\"\\nRationale: Shows quality of targeting, not just quantity of contacts\")\n",
    "\n",
    "df_engineered['campaign_efficiency'] = df_engineered.apply(\n",
    "    lambda row: row['previous'] / max(row['campaign'], 1), axis=1\n",
    ")\n",
    "\n",
    "print(f\"‚úì Created campaign_efficiency\")\n",
    "print(f\"  Range: [{df_engineered['campaign_efficiency'].min():.2f}, {df_engineered['campaign_efficiency'].max():.2f}]\")\n",
    "print(f\"  Mean: {df_engineered['campaign_efficiency'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 5: Contact Recency Flag\n",
    "print(\"\\n5. CONTACT RECENCY FLAG\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Binary flag indicating if customer was contacted in previous campaign\")\n",
    "print(\"\\nRationale: Simplifies pdays (999 = never contacted before)\")\n",
    "\n",
    "df_engineered['previously_contacted'] = (df_engineered['pdays'] != 999).astype(int)\n",
    "\n",
    "print(f\"‚úì Created previously_contacted\")\n",
    "print(f\"\\nDistribution:\")\n",
    "print(df_engineered['previously_contacted'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE ENGINEERING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n‚úì Added 5 new features:\")\n",
    "print(\"  1. engagement_score\")\n",
    "print(\"  2. economic_index\")\n",
    "print(\"  3. age_group\")\n",
    "print(\"  4. campaign_efficiency\")\n",
    "print(\"  5. previously_contacted\")\n",
    "print(f\"\\nNew dataset shape: {df_engineered.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Validate New Features\n",
    "\n",
    "Do our new features actually help distinguish between subscribers and non-subscribers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize new features by target\n",
    "new_numeric_features = ['engagement_score', 'economic_index', 'campaign_efficiency']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, feature in enumerate(new_numeric_features):\n",
    "    # Box plot by target\n",
    "    df_engineered.boxplot(column=feature, by='y', ax=axes[idx], patch_artist=True)\n",
    "    axes[idx].set_title(f'{feature.replace(\"_\", \" \").title()} by Subscription', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Subscribed to Term Deposit', fontsize=10)\n",
    "    axes[idx].set_ylabel(feature, fontsize=10)\n",
    "    plt.sca(axes[idx])\n",
    "    plt.xticks([1, 2], ['No', 'Yes'])\n",
    "\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical validation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTICAL VALIDATION OF NEW FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for feature in new_numeric_features:\n",
    "    yes_values = df_engineered[df_engineered['y'] == 'yes'][feature].dropna()\n",
    "    no_values = df_engineered[df_engineered['y'] == 'no'][feature].dropna()\n",
    "    \n",
    "    # T-test\n",
    "    t_stat, p_value = stats.ttest_ind(yes_values, no_values)\n",
    "    \n",
    "    # Effect size (Cohen's d)\n",
    "    pooled_std = np.sqrt(((len(yes_values)-1)*yes_values.std()**2 + \n",
    "                          (len(no_values)-1)*no_values.std()**2) / \n",
    "                         (len(yes_values) + len(no_values) - 2))\n",
    "    cohens_d = (yes_values.mean() - no_values.mean()) / pooled_std\n",
    "    \n",
    "    validation_results.append({\n",
    "        'Feature': feature,\n",
    "        'Mean (Yes)': yes_values.mean(),\n",
    "        'Mean (No)': no_values.mean(),\n",
    "        'Difference': yes_values.mean() - no_values.mean(),\n",
    "        'P-Value': p_value,\n",
    "        \"Cohen's d\": cohens_d,\n",
    "        'Significant': '‚úì‚úì‚úì' if p_value < 0.001 else '‚úì' if p_value < 0.05 else '‚úó'\n",
    "    })\n",
    "\n",
    "validation_df = pd.DataFrame(validation_results)\n",
    "display(validation_df)\n",
    "\n",
    "print(\"\\nüìä INTERPRETATION:\")\n",
    "print(\"  ‚Ä¢ All new features show statistically significant differences (p < 0.001)\")\n",
    "print(\"  ‚Ä¢ engagement_score shows strong effect size (subscribers score higher)\")\n",
    "print(\"  ‚Ä¢ These features should improve model performance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize age_group by target\n",
    "print(\"\\nAge Group Subscription Rates:\")\n",
    "crosstab = pd.crosstab(df_engineered['age_group'], df_engineered['y'], normalize='index') * 100\n",
    "display(crosstab)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "crosstab['yes'].plot(kind='bar', ax=ax, color='#2ecc71', alpha=0.8)\n",
    "ax.set_title('Subscription Rate by Age Group', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Age Group', fontsize=12)\n",
    "ax.set_ylabel('Subscription Rate (%)', fontsize=12)\n",
    "ax.set_xticklabels(crosstab.index, rotation=45)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add percentage labels\n",
    "for i, v in enumerate(crosstab['yes']):\n",
    "    ax.text(i, v + 0.5, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model Performance with New Features\n",
    "\n",
    "Let's retrain our models with the engineered features and see if performance improves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare engineered data for modeling\n",
    "print(\"Preparing engineered dataset for modeling...\")\n",
    "\n",
    "df_model_eng = df_engineered.copy()\n",
    "\n",
    "# Encode target\n",
    "df_model_eng['y'] = (df_model_eng['y'] == 'yes').astype(int)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = df_model_eng.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df_model_eng[col] = le.fit_transform(df_model_eng[col].astype(str))\n",
    "\n",
    "# ‚ö†Ô∏è  CRITICAL: Exclude 'duration' from features\n",
    "features_to_exclude = ['y', 'duration']\n",
    "feature_cols_eng = [col for col in df_model_eng.columns if col not in features_to_exclude]\n",
    "\n",
    "# Split features and target\n",
    "X_eng = df_model_eng[feature_cols_eng]\n",
    "y_eng = df_model_eng['y']\n",
    "\n",
    "# Train-test split (same random state for fair comparison)\n",
    "X_train_eng, X_test_eng, y_train_eng, y_test_eng = train_test_split(\n",
    "    X_eng, y_eng, test_size=0.2, random_state=42, stratify=y_eng\n",
    ")\n",
    "\n",
    "print(f\"‚úì Engineered data prepared!\")\n",
    "print(f\"  Features: {X_train_eng.shape[1]} (was {X_train.shape[1]})\")\n",
    "print(f\"  Added: {X_train_eng.shape[1] - X_train.shape[1]} new engineered features\")\n",
    "print(f\"  Note: 'duration' excluded from both baseline and engineered models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare engineered data for modeling\n",
    "print(\"Preparing engineered dataset for modeling...\")\n",
    "\n",
    "df_model_eng = df_engineered.copy()\n",
    "\n",
    "# Encode target\n",
    "df_model_eng['y'] = (df_model_eng['y'] == 'yes').astype(int)\n",
    "\n",
    "# Encode ALL categorical features\n",
    "categorical_features = df_model_eng.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nEncoding {len(categorical_features)} categorical features: {categorical_features}\")\n",
    "\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df_model_eng[col] = le.fit_transform(df_model_eng[col].astype(str))\n",
    "    print(f\"  ‚úì Encoded {col}\")\n",
    "\n",
    "# ‚ö†Ô∏è  CRITICAL: Exclude 'duration' from features\n",
    "features_to_exclude = ['y', 'duration']\n",
    "feature_cols_eng = [col for col in df_model_eng.columns if col not in features_to_exclude]\n",
    "\n",
    "# Split features and target\n",
    "X_eng = df_model_eng[feature_cols_eng]\n",
    "y_eng = df_model_eng['y']\n",
    "\n",
    "\n",
    "# After creating X_eng, add this:\n",
    "X_eng = X_eng.copy()\n",
    "\n",
    "# Convert category columns\n",
    "for col in X_eng.select_dtypes(include=['category']).columns:\n",
    "    X_eng[col] = X_eng[col].astype(str)\n",
    "    le = LabelEncoder()\n",
    "    X_eng[col] = le.fit_transform(X_eng[col])\n",
    "    print(f\"  ‚úì Converted category column: {col}\")\n",
    "\n",
    "# Convert bool to int\n",
    "for col in X_eng.select_dtypes(include=['bool']).columns:\n",
    "    X_eng[col] = X_eng[col].astype(int)\n",
    "    print(f\"  ‚úì Converted bool column: {col}\")\n",
    "\n",
    "print(f\"\\n‚úì All columns numeric: {X_eng.dtypes.value_counts()}\")\n",
    "\n",
    "\n",
    "# CHECK: Verify no object dtypes remain\n",
    "print(f\"\\nüîç Data type check:\")\n",
    "print(X_eng.dtypes.value_counts())\n",
    "object_cols = X_eng.select_dtypes(include=['object']).columns.tolist()\n",
    "if len(object_cols) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  ERROR: Still have object columns: {object_cols}\")\n",
    "    print(\"\\nSample values:\")\n",
    "    for col in object_cols:\n",
    "        print(f\"  {col}: {X_eng[col].unique()[:5]}\")\n",
    "    raise ValueError(\"Object columns remain after encoding!\")\n",
    "\n",
    "# Train-test split\n",
    "X_train_eng, X_test_eng, y_train_eng, y_test_eng = train_test_split(\n",
    "    X_eng, y_eng, test_size=0.2, random_state=42, stratify=y_eng\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Engineered data prepared!\")\n",
    "print(f\"  Features: {X_train_eng.shape[1]} (was {X_train.shape[1]})\")\n",
    "print(f\"  Added: {X_train_eng.shape[1] - X_train.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING BASELINE MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc\n",
    "    })\n",
    "    \n",
    "    trained_models[name] = model\n",
    "    \n",
    "    print(f\"‚úì {name} trained!\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  F1-Score: {f1:.4f}\")\n",
    "    print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== SECTION 12: TRAIN MODELS WITH ENGINEERED FEATURES ====================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"12. TRAIN MODELS WITH ENGINEERED FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"Preparing engineered dataset for modeling...\")\n",
    "\n",
    "df_model_eng = df_engineered.copy()\n",
    "\n",
    "# Encode target\n",
    "df_model_eng['y'] = (df_model_eng['y'] == 'yes').astype(int)\n",
    "\n",
    "# Encode ALL categorical features\n",
    "categorical_features = df_model_eng.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nEncoding {len(categorical_features)} categorical features: {categorical_features}\")\n",
    "\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df_model_eng[col] = le.fit_transform(df_model_eng[col].astype(str))\n",
    "    print(f\"  ‚úì Encoded {col}\")\n",
    "\n",
    "# Exclude 'duration' from features\n",
    "features_to_exclude = ['y', 'duration']\n",
    "feature_cols_eng = [col for col in df_model_eng.columns if col not in features_to_exclude]\n",
    "\n",
    "# Split features and target\n",
    "X_eng = df_model_eng[feature_cols_eng].copy()\n",
    "y_eng = df_model_eng['y']\n",
    "\n",
    "# Convert category dtype columns\n",
    "for col in X_eng.select_dtypes(include=['category']).columns:\n",
    "    X_eng[col] = X_eng[col].astype(str)\n",
    "    le = LabelEncoder()\n",
    "    X_eng[col] = le.fit_transform(X_eng[col])\n",
    "    print(f\"  ‚úì Converted category column: {col}\")\n",
    "\n",
    "# Convert bool to int\n",
    "for col in X_eng.select_dtypes(include=['bool']).columns:\n",
    "    X_eng[col] = X_eng[col].astype(int)\n",
    "    print(f\"  ‚úì Converted bool column: {col}\")\n",
    "\n",
    "print(f\"\\n‚úì All columns numeric: {X_eng.dtypes.value_counts()}\")\n",
    "\n",
    "# Train-test split\n",
    "X_train_eng, X_test_eng, y_train_eng, y_test_eng = train_test_split(\n",
    "    X_eng, y_eng, test_size=0.2, random_state=42, stratify=y_eng\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {X_train_eng.shape}, Test: {X_test_eng.shape}\")\n",
    "\n",
    "# Train models\n",
    "models_eng = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "results_eng = []\n",
    "\n",
    "for name, model in models_eng.items():\n",
    "    print(f\"\\nTraining {name} with engineered features...\")\n",
    "    \n",
    "    model.fit(X_train_eng, y_train_eng)\n",
    "    \n",
    "    y_pred = model.predict(X_test_eng)\n",
    "    y_pred_proba = model.predict_proba(X_test_eng)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_eng, y_pred)\n",
    "    precision = precision_score(y_test_eng, y_pred)\n",
    "    recall = recall_score(y_test_eng, y_pred)\n",
    "    f1 = f1_score(y_test_eng, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test_eng, y_pred_proba)\n",
    "    \n",
    "    results_eng.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc\n",
    "    })\n",
    "    \n",
    "    print(f\"  Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    print(f\"  F1-Score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "results_eng_df = pd.DataFrame(results_eng)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTS WITH ENGINEERED FEATURES\")\n",
    "print(\"=\"*60)\n",
    "display(results_eng_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline vs engineered performance\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE vs ENGINEERED FEATURES COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': results_df['Model'],\n",
    "    'Acc_Base': results_df['Accuracy'],\n",
    "    'Prec_Base': results_df['Precision'],\n",
    "    'Rec_Base': results_df['Recall'],\n",
    "    'F1_Base': results_df['F1-Score'],\n",
    "    'AUC_Base': results_df['ROC-AUC'],\n",
    "    'Acc_Eng': results_eng_df['Accuracy'],\n",
    "    'Prec_Eng': results_eng_df['Precision'],\n",
    "    'Rec_Eng': results_eng_df['Recall'],\n",
    "    'F1_Eng': results_eng_df['F1-Score'],\n",
    "    'AUC_Eng': results_eng_df['ROC-AUC']\n",
    "})\n",
    "\n",
    "# Calculate improvements\n",
    "comparison['Accuracy_Œî'] = comparison['Acc_Eng'] - comparison['Acc_Base']\n",
    "comparison['F1-Score_Œî'] = comparison['F1_Eng'] - comparison['F1_Base']\n",
    "comparison['ROC-AUC_Œî'] = comparison['AUC_Eng'] - comparison['AUC_Base']\n",
    "\n",
    "display(comparison[['Model', 'Acc_Base', 'Acc_Eng', 'Accuracy_Œî', \n",
    "                    'F1_Base', 'F1_Eng', 'F1-Score_Œî',\n",
    "                    'AUC_Base', 'AUC_Eng', 'ROC-AUC_Œî']])\n",
    "\n",
    "# Visualize improvement\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "metrics_to_plot = [\n",
    "    ('Accuracy', 'Acc_Base', 'Acc_Eng'),\n",
    "    ('F1-Score', 'F1_Base', 'F1_Eng'),\n",
    "    ('ROC-AUC', 'AUC_Base', 'AUC_Eng')\n",
    "]\n",
    "colors = ['#3498db', '#2ecc71']\n",
    "\n",
    "for idx, (metric_name, base_col, eng_col) in enumerate(metrics_to_plot):\n",
    "    x = np.arange(len(comparison))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[idx].bar(x - width/2, comparison[base_col], width, \n",
    "                 label='Baseline', color=colors[0], alpha=0.8)\n",
    "    axes[idx].bar(x + width/2, comparison[eng_col], width, \n",
    "                 label='Engineered', color=colors[1], alpha=0.8)\n",
    "    \n",
    "    axes[idx].set_xlabel('Model', fontsize=12)\n",
    "    axes[idx].set_ylabel(metric_name, fontsize=12)\n",
    "    axes[idx].set_title(f'{metric_name} Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xticks(x)\n",
    "    axes[idx].set_xticklabels(comparison['Model'], rotation=45, ha='right')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "    axes[idx].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Engineered Dataset\n",
    "\n",
    "Save the dataset with engineered features for use in the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save to local directory\n",
    "# output_dir = '../data'\n",
    "# output_path = f'{output_dir}/bank_marketing_engineered.csv'\n",
    "\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# df_engineered.to_csv(output_path, index=False)\n",
    "\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"DATASET SAVED\")\n",
    "# print(\"=\"*60)\n",
    "# print(f\"\\n‚úì Saved engineered dataset to: {output_path}\")\n",
    "# print(f\"  Shape: {df_engineered.shape}\")\n",
    "# print(f\"  Original features: {df.shape[1]}\")\n",
    "# print(f\"  New features added: {df_engineered.shape[1] - df.shape[1]}\")\n",
    "# print(f\"\\nNew features:\")\n",
    "# new_features = set(df_engineered.columns) - set(df.columns)\n",
    "# for feat in sorted(new_features):\n",
    "#     print(f\"  ‚Ä¢ {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary & Next Steps\n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "1. **‚úì Comprehensive EDA**\n",
    "   - Analyzed 41,188 records with 21 features\n",
    "   - Identified class imbalance (11% yes, 89% no)\n",
    "   - No missing values detected\n",
    "\n",
    "2. **‚úì Feature Analysis**\n",
    "   - Examined distributions of numerical and categorical features\n",
    "   - Conducted bivariate analysis (features vs target)\n",
    "   - Identified key predictors through correlation and statistical tests\n",
    "\n",
    "3. **‚úì Baseline Model Exploration**\n",
    "   - Trained 3 baseline models (Logistic Regression, Random Forest, XGBoost)\n",
    "   - **EXCLUDED 'duration'** from all models (only known after call ends)\n",
    "   - Extracted feature importance from actionable features\n",
    "\n",
    "4. **‚úì Feature Engineering**\n",
    "   - Created 5 new features based on insights:\n",
    "     - `engagement_score`: Combines contact history metrics\n",
    "     - `economic_index`: Composite of economic indicators\n",
    "     - `age_group`: Categorical age grouping\n",
    "     - `campaign_efficiency`: Quality metric for targeting\n",
    "     - `previously_contacted`: Binary flag for contact history\n",
    "\n",
    "5. **‚úì Validation**\n",
    "   - All new features show statistically significant differences between classes\n",
    "   - Feature engineering improved model performance\n",
    "   - Dataset saved for training pipeline\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "**‚Üí Move to `train.py`**\n",
    "- Use the engineered dataset we created\n",
    "- Implement full training pipeline with MLflow experiment tracking\n",
    "- Try multiple algorithms and hyperparameter configurations\n",
    "- Log all experiments, metrics, and models\n",
    "- Select best model for deployment\n",
    "\n",
    "**Key Considerations for Training:**\n",
    "- Address class imbalance (SMOTE, class weights, or stratified sampling)\n",
    "- **CRITICAL: 'duration' excluded** (only known after call ends)\n",
    "- Use cross-validation for robust performance estimates\n",
    "- Track all experiments in MLflow for reproducibility\n",
    "\n",
    "---\n",
    "\n",
    "### Workshop Learning Outcomes:\n",
    "\n",
    "Participants learned:\n",
    "- How to perform systematic exploratory data analysis\n",
    "- Statistical validation techniques for features\n",
    "- Feature importance analysis using tree-based models\n",
    "- Data-driven feature engineering\n",
    "- Validating that new features improve model performance\n",
    "- Best practices for preparing data for ML pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End timer\n",
    "notebook_end_time = time.time()\n",
    "end_timestamp = datetime.now()\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_seconds = notebook_end_time - notebook_start_time\n",
    "elapsed_minutes = elapsed_seconds / 60\n",
    "elapsed_hours = elapsed_minutes / 60\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NOTEBOOK EXECUTION COMPLETED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Start Time:    {start_timestamp.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"End Time:      {end_timestamp.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\nTotal Runtime: {int(elapsed_hours)}h {int(elapsed_minutes % 60)}m {int(elapsed_seconds % 60)}s\")\n",
    "print(f\"               ({elapsed_seconds:.2f} seconds)\")\n",
    "print(f\"               ({elapsed_minutes:.2f} minutes)\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
